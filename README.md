# ü§ñ Classifica√ß√£o de Sentimento com BERT

Este reposit√≥rio cont√©m o c√≥digo de um projeto de Intelig√™ncia Artificial para classificar o sentimento (positivo, negativo ou neutro) de coment√°rios em portugu√™s usando o modelo BERT.

O projeto treina **tr√™s modelos de classifica√ß√£o independentes** para analisar o sentimento em tr√™s t√≥picos distintos:
1.  On√ßa
2.  Caseiro
3.  Not√≠cia

O c√≥digo principal est√° documentado no notebook Jupyter (`.ipynb`) e foi desenvolvido para ser executado no ambiente Google Colab com acelera√ß√£o de GPU.

---

## üéØ Metodologia

O pipeline do projeto segue 5 etapas principais:

1.  **Prepara√ß√£o dos Dados:** Os dados s√£o lidos, limpos e os r√≥tulos de texto (ex: "positivo") s√£o convertidos em n√∫meros (ex: 2). O conjunto de dados √© dividido em **Treino (70%)**, **Valida√ß√£o (15%)** e **Teste (15%)** usando uma divis√£o estratificada √∫nica para evitar vazamento de dados (`data leakage`) entre os tr√™s modelos.
2.  **Tokeniza√ß√£o:** Usamos o `AutoTokenizer` do modelo `neuralmind/bert-base-portugu√™s-cased` para converter os textos em tensores (`input_ids` e `attention_mask`) que o BERT entende.
3.  **Modelo:** Carregamos tr√™s inst√¢ncias independentes de `BertForSequenceClassification` com uma cabe√ßa de classifica√ß√£o de 3 r√≥tulos.
4.  **Treinamento:** Cada modelo √© treinado por 10 √©pocas usando o otimizador `AdamW` (lr=2e-5). O *loss* e a acur√°cia de treino/valida√ß√£o s√£o monitorados a cada √©poca.
5.  **Avalia√ß√£o:** Os modelos finais s√£o avaliados no conjunto de teste (15% dos dados nunca vistos) usando o `classification_report` do Scikit-learn para medir Precision, Recall e F1-Score.

---

## üìä Resultados Finais (Acur√°cia no Teste)

Os modelos treinados alcan√ßaram os seguintes resultados no conjunto de teste:

| Modelo | Acur√°cia Geral | F1-Score (Macro Avg) |
| :--- | :---: | :---: |
| **On√ßa** | 81% | 0.67 |
| **Caseiro** | 87% | 0.68 |
| **Not√≠cia** | 94% | 0.80 |

O modelo **Not√≠cia** foi o de melhor desempenho, demonstrando alta capacidade de generaliza√ß√£o para classificar as tr√™s classes (boa, ruim, neutra) com efic√°cia.

---

## üöÄ Como Executar

1.  Abra o arquivo `.ipynb` no [Google Colab](https://colab.research.google.com/).
2.  Certifique-se de que o ambiente de execu√ß√£o est√° configurado para usar um **acelerador de hardware (GPU)**.
    * (Ambiente de execu√ß√£o -> Alterar o tipo de ambiente de execu√ß√£o -> T4 GPU)
3.  Execute todas as c√©lulas em ordem.
