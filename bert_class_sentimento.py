# -*- coding: utf-8 -*-
"""BERT_Class_Sentimento.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17hSTQZERMPxx9mQ3KizzHwQXkoWiU3se

# üöÄ Classifica√ß√£o de Sentimento com BERT

**Objetivo:** Treinar 3 modelos BERT (`neuralmind/bert-base-portuguese-cased`) para classificar o sentimento (positivo, negativo ou neutro) de coment√°rios sobre 3 t√≥picos distintos: "On√ßa", "Caseiro" e "Not√≠cia".

**Autor:** Lucas Vinicius da Luz Ferreira
"""

!pip install transformers torch

import torch
import time
import datetime
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, get_linear_schedule_with_warmup
from torch.optim import AdamW
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from transformers import BertForSequenceClassification, AutoConfig
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler

"""## 1. üßπ Prepara√ß√£o dos Dados

Nesta etapa, foi feito todo o pr√©-processamento dos dados:
1.  Foi carregado o arquivo CSV usando o Pandas.
2.  Foi removida as linhas com textos vazios ou duplicados.
3.  Foram convertidos os r√≥tulos de texto (ex: "negativo", "neutro", "positivo") para n√∫meros (0, 1, 2) para cada uma das 3 classes.
4.  Foi dividido o DataFrame *inteiro* (85% / 15%) e depois (70% / 15%) para criar os conjuntos de **Treino (70%)**, **Valida√ß√£o (15%)** e **Teste (15%)**.
    * Usar `train_test_split` no DataFrame garante que n√£o h√° **vazamento de dados (data leakage)**, pois o mesmo coment√°rio estar√° sempre no mesmo conjunto para os 3 modelos.
"""

url = "https://docs.google.com/spreadsheets/d/17aHYyRNfbmde8bVOR_HX_BmNUEdkygPuaGO4lJj26jg/export?format=csv&gid=0"
planilha = pd.read_csv(url)

planilha_filtrada = planilha[
      planilha['onca'].notna() & (planilha['onca'].str.strip() != "")
    & planilha['caseiro'].notna() & (planilha['caseiro'].str.strip() != "")
    & planilha['not√≠cia'].notna() & (planilha['not√≠cia'].str.strip() != "")
    & planilha['comment_text'].notna() & (planilha['comment_text'].str.strip() != "")
]

planilha_final = planilha_filtrada.drop_duplicates(subset=['comment_text'])

mapeamento = {'positivo': 2, 'neutro': 1, 'negativo': 0}

planilha_final['onca'] = planilha_final['onca'].str.lower().str.strip().map(mapeamento)
planilha_final['caseiro'] = planilha_final['caseiro'].str.lower().str.strip().map(mapeamento)
planilha_final['not√≠cia'] = planilha_final['not√≠cia'].str.lower().str.strip().map({'boa': 2, 'neutra': 1, 'ruim': 0})

temp_restante, temp_teste = train_test_split(planilha_final, test_size=0.15, random_state=42, stratify=planilha_final['onca'])
temp_treino, temp_valid = train_test_split(temp_restante, test_size=0.17647, random_state=42, stratify=temp_restante['onca'])

# Onca
X_treino_onca, y_treino_onca = temp_treino['comment_text'], temp_treino['onca']
X_valid_onca, y_valid_onca = temp_valid['comment_text'], temp_valid['onca']
X_teste_onca, y_teste_onca = temp_teste['comment_text'], temp_teste['onca']
# Caseiro
X_treino_caseiro, y_treino_caseiro = temp_treino['comment_text'], temp_treino['caseiro']
X_valid_caseiro, y_valid_caseiro = temp_valid['comment_text'], temp_valid['caseiro']
X_teste_caseiro, y_teste_caseiro = temp_teste['comment_text'], temp_teste['caseiro']
# Noticia
X_treino_noticia, y_treino_noticia = temp_treino['comment_text'], temp_treino['not√≠cia']
X_valid_noticia, y_valid_noticia = temp_valid['comment_text'], temp_valid['not√≠cia']
X_teste_noticia, y_teste_noticia = temp_teste['comment_text'], temp_teste['not√≠cia']

"""## 2. Tokeniza√ß√£o e DataLoaders

Com os dados divididos, os mesmos foram preparados para o BERT:
1.  Foi instaciado o `AutoTokenizer` do modelo `neuralmind/bert-base-portuguese-cased`.
2.  Foi criada uma fun√ß√£o que converte as listas de coment√°rios em tensores PyTorch:
    * `input_ids`: Os IDs de cada token (palavra).
    * `attention_mask`: A m√°scara que diz ao modelo quais tokens s√£o palavras reais e quais s√£o preenchimento (`[PAD]`).
3.  Foram Empacotados os tensores (`input_ids`, `attention_mask` e `rotulos`) em `TensorDataset` e, em seguida, em `DataLoader`. Isso permite que o modelo acesse os dados em lotes (`BATCH_SIZE`) durante o treinamento.
    * Foram criados 9 DataLoaders no total (treino/val/teste para On√ßa, Caseiro e Not√≠cia).
"""

MODELO = 'neuralmind/bert-base-portuguese-cased'

if torch.cuda.is_available():
    device = torch.device('cuda')
    print(f'Usando GPU: {torch.cuda.get_device_name(0)}')
else:
    device = torch.device('cpu')
    print('Usando CPU (O treinamento ser√° lento).')

tokenizador = AutoTokenizer.from_pretrained(MODELO)

MAX = 128
BATCH_SIZE = 16

def codificar_textos(tokenizador, texto, maximo):
    encoded_batch = tokenizador.batch_encode_plus(
        texto.tolist(),
        add_special_tokens=True,
        max_length=maximo,
        padding='max_length',
        truncation=True,
        return_attention_mask=True,
        return_tensors='pt'
    )
    return encoded_batch['input_ids'], encoded_batch['attention_mask']

# Onca
input_ids_treino_onca, attention_masks_treino_onca = codificar_textos(tokenizador, X_treino_onca, MAX)
input_ids_valid_onca, attention_masks_valid_onca = codificar_textos(tokenizador, X_valid_onca, MAX)
input_ids_teste_onca, attention_masks_teste_onca = codificar_textos(tokenizador, X_teste_onca, MAX)

rotulos_treino_onca = torch.tensor(y_treino_onca.values)
rotulos_valid_onca = torch.tensor(y_valid_onca.values)
rotulos_teste_onca = torch.tensor(y_teste_onca.values)

dataset_treino_onca = TensorDataset(input_ids_treino_onca, attention_masks_treino_onca, rotulos_treino_onca)
dataset_valid_onca = TensorDataset(input_ids_valid_onca, attention_masks_valid_onca, rotulos_valid_onca)
dataset_teste_onca = TensorDataset(input_ids_teste_onca, attention_masks_teste_onca, rotulos_teste_onca)

dataloader_treino_onca = DataLoader(
    dataset_treino_onca,
    sampler=RandomSampler(dataset_treino_onca),
    batch_size=BATCH_SIZE
)

dataloader_valid_onca = DataLoader(
    dataset_valid_onca,
    sampler=SequentialSampler(dataset_valid_onca),
    batch_size=BATCH_SIZE
)

dataloader_teste_onca = DataLoader(
    dataset_teste_onca,
    sampler=SequentialSampler(dataset_teste_onca),
    batch_size=BATCH_SIZE
)

# Caseiro
input_ids_treino_caseiro, attention_masks_treino_caseiro = codificar_textos(tokenizador, X_treino_caseiro, MAX)
input_ids_valid_caseiro, attention_masks_valid_caseiro = codificar_textos(tokenizador, X_valid_caseiro, MAX)
input_ids_teste_caseiro, attention_masks_teste_caseiro = codificar_textos(tokenizador, X_teste_caseiro, MAX)

rotulos_treino_caseiro = torch.tensor(y_treino_caseiro.values)
rotulos_valid_caseiro = torch.tensor(y_valid_caseiro.values)
rotulos_teste_caseiro = torch.tensor(y_teste_caseiro.values)

dataset_treino_caseiro = TensorDataset(input_ids_treino_caseiro, attention_masks_treino_caseiro, rotulos_treino_caseiro)
dataset_valid_caseiro = TensorDataset(input_ids_valid_caseiro, attention_masks_valid_caseiro, rotulos_valid_caseiro)
dataset_teste_caseiro = TensorDataset(input_ids_teste_caseiro, attention_masks_teste_caseiro, rotulos_teste_caseiro)

dataloader_treino_caseiro = DataLoader(
    dataset_treino_caseiro,
    sampler=RandomSampler(dataset_treino_caseiro),
    batch_size=BATCH_SIZE
)

dataloader_valid_caseiro = DataLoader(
    dataset_valid_caseiro,
    sampler=SequentialSampler(dataset_valid_caseiro),
    batch_size=BATCH_SIZE
)

dataloader_teste_caseiro = DataLoader(
    dataset_teste_caseiro,
    sampler=SequentialSampler(dataset_teste_caseiro),
    batch_size=BATCH_SIZE
)

# Noticia
input_ids_treino_noticia, attention_masks_treino_noticia = codificar_textos(tokenizador, X_treino_noticia, MAX)
input_ids_valid_noticia, attention_masks_valid_noticia = codificar_textos(tokenizador, X_valid_noticia, MAX)
input_ids_teste_noticia, attention_masks_teste_noticia = codificar_textos(tokenizador, X_teste_noticia, MAX)

rotulos_treino_noticia = torch.tensor(y_treino_noticia.values)
rotulos_valid_noticia = torch.tensor(y_valid_noticia.values)
rotulos_teste_noticia = torch.tensor(y_teste_noticia.values)

dataset_treino_noticia = TensorDataset(input_ids_treino_noticia, attention_masks_treino_noticia, rotulos_treino_noticia)
dataset_valid_noticia = TensorDataset(input_ids_valid_noticia, attention_masks_valid_noticia, rotulos_valid_noticia)
dataset_teste_noticia = TensorDataset(input_ids_teste_noticia, attention_masks_teste_noticia, rotulos_teste_noticia)

dataloader_treino_noticia = DataLoader(
    dataset_treino_noticia,
    sampler=RandomSampler(dataset_treino_noticia),
    batch_size=BATCH_SIZE
)

dataloader_valid_noticia = DataLoader(
    dataset_valid_noticia,
    sampler=SequentialSampler(dataset_valid_noticia),
    batch_size=BATCH_SIZE
)

dataloader_teste_noticia = DataLoader(
    dataset_teste_noticia,
    sampler=SequentialSampler(dataset_teste_noticia),
    batch_size=BATCH_SIZE
)

"""## 3. Defini√ß√£o do Modelo

Aqui, foi carregada a arquitetura do modelo BERT pr√©-treinado:
1.  Foi usado `AutoConfig` para definir o n√∫mero de r√≥tulos de sa√≠da: `num_labels=3`.
2.  Foi usado `BertForSequenceClassification`. Esta arquitetura j√° usa o token `[CLS]` (que representa a frase inteira) por padr√£o para a tarefa de classifica√ß√£o.
3.  Foram criadas **3 inst√¢ncias independentes** do modelo (`modelo_onca`, `modelo_caseiro`, `modelo_noticia`) e as movemos para o `device` (GPU).
"""

parametro = AutoConfig.from_pretrained(
    MODELO,
    num_labels=3,
    output_attentions=False,
    output_hidden_states=False,
)

modelo_onca = BertForSequenceClassification.from_pretrained(
    MODELO,
    config=parametro
)

modelo_caseiro = BertForSequenceClassification.from_pretrained(
    MODELO,
    config=parametro
)

modelo_noticia = BertForSequenceClassification.from_pretrained(
    MODELO,
    config=parametro
)

modelo_onca.to(device)
modelo_caseiro.to(device)
modelo_noticia.to(device)

"""## 4. Treinamento e Valida√ß√£o

Esta √© a etapa principal onde os modelos aprendem:
1.  Foi criada a fun√ß√£o `treinar_modelo` que recebe um modelo e seus dataloaders.
2.  Foi usado o `AdamW` com a taxa de aprendizado (`lr`) de `2e-5`.
3.  Foram iterados por 10 √©pocas.
    Foi calculado o `loss` e a acur√°cia nos dados de treino.
    O `loss` e a acur√°cia foram calculados nos dados de valida√ß√£o para monitorar o aprendizado.
4.  Foi chamada a fun√ß√£o `treinar_modelo` 3 vezes, uma para cada modelo.
5.  Exibimos nos gr√°ficos a evolu√ß√£o do *Loss* (Treino vs. Valida√ß√£o) para analisar visualmente.
"""

def formatar_tempo(segundos):
    return str(datetime.timedelta(seconds=int(round(segundos))))

def treinar_modelo(modelo, dataloader_treino, dataloader_valid, device, epocas):
    otimizador = AdamW(modelo.parameters(), lr=2e-5, eps=1e-8)
    total_passos = len(dataloader_treino) * epocas
    lr_scheduler = get_linear_schedule_with_warmup(otimizador,
                                                num_warmup_steps=0,
                                                num_training_steps=total_passos)

    estatisticas = []

    print(f'Iniciando treinamento por {epocas} √©pocas')

    for epoca in range(1, epocas + 1):
        print(f'\n √âpoca {epoca}/{epocas}')
        epoca_ini = time.time()

        # TREINO
        modelo.train()
        treino_loss_soma = 0.0
        treino_acertos = 0
        treino_amostras = 0

        for batch in dataloader_treino:
            input_ids, attention_mask, rotulos = batch
            input_ids = input_ids.to(device)
            attention_mask = attention_mask.to(device)
            rotulos = rotulos.to(device)

            otimizador.zero_grad()

            outputs = modelo(input_ids,
                            token_type_ids=None,
                            attention_mask=attention_mask,
                            labels=rotulos)
            loss = outputs.loss
            logits = outputs.logits

            loss.backward()
            torch.nn.utils.clip_grad_norm_(modelo.parameters(), 1.0)
            otimizador.step()
            lr_scheduler.step()

            batch_size = rotulos.size(0)
            treino_loss_soma += loss.item() * batch_size

            preds = torch.argmax(logits, dim=1)
            treino_acertos += (preds == rotulos).sum().item()
            treino_amostras += batch_size

        avg_treino_loss = treino_loss_soma / treino_amostras
        treino_acuracia = treino_acertos / treino_amostras

        # VALIDA√á√ÉO
        modelo.eval()
        valid_loss_soma = 0.0
        valid_acertos = 0
        valid_amostras = 0

        with torch.no_grad():
            for batch in dataloader_valid:
                input_ids, attention_mask, rotulos = batch
                input_ids = input_ids.to(device)
                attention_mask = attention_mask.to(device)
                rotulos = rotulos.to(device)

                outputs = modelo(input_ids,
                                token_type_ids=None,
                                attention_mask=attention_mask,
                                labels=rotulos)
                loss = outputs.loss
                logits = outputs.logits

                batch_size = rotulos.size(0)
                valid_loss_soma += loss.item() * batch_size

                preds = torch.argmax(logits, dim=1)
                valid_acertos += (preds == rotulos).sum().item()
                valid_amostras += batch_size

        avg_valid_loss = valid_loss_soma / valid_amostras
        valid_accuracy = valid_acertos / valid_amostras

        epoca_time = formatar_tempo(time.time() - epoca_ini)

        print(f'Treino Loss: {avg_treino_loss:.4f} | Treino Acc: {treino_acuracia:.4f}')
        print(f'Valida√ß√£o Loss: {avg_valid_loss:.4f} | Valida√ß√£o Acc: {valid_accuracy:.4f}')
        print(f'Tempo da √©poca: {epoca_time}')

        estatisticas.append({
            'epoca': epoca,
            'treino_loss': avg_treino_loss,
            'valid_loss': avg_valid_loss,
            'treino_acc': treino_acuracia,
            'valid_acc': valid_accuracy,
            'epoca_time': epoca_time
        })

    print('Treinamento conclu√≠do.')
    return estatisticas

def grafico_loss(estatisticas):
    estatisticas_df = pd.DataFrame(data=estatisticas)
    estatisticas_df = estatisticas_df.set_index('epoca')

    plt.figure(figsize=(10, 5))
    plt.plot(estatisticas_df['treino_loss'], 'b-o', label='Treino')
    plt.plot(estatisticas_df['valid_loss'], 'g-o', label='Valida√ß√£o')

    plt.title('Evolu√ß√£o do Loss (Treino vs. Valida√ß√£o)')
    plt.xlabel('√âpoca')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    plt.xticks(range(1, len(estatisticas_df) + 1))
    plt.show()

EPOCA = 10

estatistica_onca = treinar_modelo(
    modelo_onca,
    dataloader_treino_onca,
    dataloader_valid_onca,
    device,
    EPOCA
)

estatistica_caseiro = treinar_modelo(
    modelo_caseiro,
    dataloader_treino_caseiro,
    dataloader_valid_caseiro,
    device,
    EPOCA
)

estatistica_noticia = treinar_modelo(
    modelo_noticia,
    dataloader_treino_noticia,
    dataloader_valid_noticia,
    device,
    EPOCA
)

grafico_loss(estatistica_onca)

grafico_loss(estatistica_caseiro)

grafico_loss(estatistica_noticia)

"""## 5. Avalia√ß√£o Final (Conjunto de Teste)

Com os modelos treinados, fizemos a avalia√ß√£o final no conjunto de Teste:
1.  Foi criada a fun√ß√£o `testar_modelo` que passa os dados de teste pelo modelo (com `torch.no_grad()`) e coleta as previs√µes (`preds`) e os r√≥tulos reais (`rotulos`).
2.  Foi usado o `classification_report` do Scikit-learn para gerar as m√©tricas finais para cada classe:
    * **Precision**
    * **Recall**
    * **F1-Score**
    * **Acur√°cia Geral**
3.  Por fim, Filtramos e exibimos 2 exemplos de coment√°rios que cada modelo classificou incorretamente, para an√°lise qualitativa.
"""

def testar_modelo(modelo, dataloader_teste, device):
  modelo.eval()
  preds_list = []
  rotulos_list = []

  with torch.no_grad():
    for batch in dataloader_teste:
      t_input_ids = batch[0].to(device)
      t_input_mask = batch[1].to(device)
      t_rotulos = batch[2].to(device)

      outputs = modelo(t_input_ids, token_type_ids=None, attention_mask=t_input_mask)

      logits = outputs.logits

      logits = logits.detach().cpu().numpy()
      rotulos = t_rotulos.to('cpu').numpy()

      preds = np.argmax(logits, axis=1).flatten()

      preds_list.extend(preds)
      rotulos_list.extend(rotulos)

  return preds_list, rotulos_list

previsoes_onca, rotulos_onca = testar_modelo(
    modelo_onca,
    dataloader_teste_onca,
    device
)

previsoes_caseiro, rotulos_caseiro = testar_modelo(
    modelo_caseiro,
    dataloader_teste_caseiro,
    device
)

previsoes_noticia, rotulos_noticia = testar_modelo(
    modelo_noticia,
    dataloader_teste_noticia,
    device
)

print('\n Classifica√ß√£o (On√ßa)')
print(classification_report(rotulos_onca, previsoes_onca, target_names=['negativo', 'neutro', 'positivo']))
print('\n Classifica√ß√£o (Caseiro)')
print(classification_report(rotulos_caseiro, previsoes_caseiro, target_names=['negativo', 'neutro', 'positivo']))
print('\n Classifica√ß√£o (Not√≠cia)')
print(classification_report(rotulos_noticia, previsoes_noticia, target_names=['ruim', 'neutra', 'boa']))

print('\nErros (On√ßa)')
erros = pd.DataFrame({
    'comentario': X_teste_onca,
    'rotulo': rotulos_onca,
    'previsto': previsoes_onca
})

mapeamento_inverso = {0: 'negativo', 1: 'neutro', 2: 'positivo'}
erros['rotulo_desc'] = erros['rotulo'].map(mapeamento_inverso)
erros['previsto_desc'] = erros['previsto'].map(mapeamento_inverso)

somente_erro = erros[erros['rotulo'] != erros['previsto']]

for i, linha in somente_erro.head(2).iterrows():
  print(f'\nComent√°rio: {linha['comentario']}')
  print(f'Rotulo: {linha['rotulo_desc']}')
  print(f'Previsto: {linha['previsto_desc']} \n')
#
print('\nErros (Caseiro)')
erros = pd.DataFrame({
    'comentario': X_teste_caseiro,
    'rotulo': rotulos_caseiro,
    'previsto': previsoes_caseiro
})

erros['rotulo_desc'] = erros['rotulo'].map(mapeamento_inverso)
erros['previsto_desc'] = erros['previsto'].map(mapeamento_inverso)

somente_erro = erros[erros['rotulo'] != erros['previsto']]

for i, linha in somente_erro.head(2).iterrows():
  print(f'\nComent√°rio: {linha['comentario']}')
  print(f'Rotulo: {linha['rotulo_desc']}')
  print(f'Previsto: {linha['previsto_desc']} \n')
#
print('\nErros (Not√≠cia)')
erros = pd.DataFrame({
    'comentario': X_teste_noticia,
    'rotulo': rotulos_noticia,
    'previsto': previsoes_noticia
})

mapeamento_inverso = {0: 'ruim', 1: 'neutra', 2: 'boa'}
erros['rotulo_desc'] = erros['rotulo'].map(mapeamento_inverso)
erros['previsto_desc'] = erros['previsto'].map(mapeamento_inverso)

somente_erro = erros[erros['rotulo'] != erros['previsto']]

for i, linha in somente_erro.head(2).iterrows():
  print(f'\nComent√°rio: {linha['comentario']}')
  print(f'Rotulo: {linha['rotulo_desc']}')
  print(f'Previsto: {linha['previsto_desc']} \n')

def classificar_texto(comentario, modelo, tokenizador, device, max_len=128):
  modelo.eval()
  revisao = tokenizador.encode_plus(
      comentario,
      add_special_tokens=True,
      max_length=max_len,
      return_attention_mask=True,
      padding='max_length',
      truncation=True,
      return_tensors='pt',
  )
  input_ids = revisao['input_ids'].to(device)
  attention_mask = revisao['attention_mask'].to(device)

  with torch.no_grad():
    outputs = modelo(input_ids, attention_mask=attention_mask)

  logits = outputs.logits
  return logits.detach().cpu().numpy()

comentario_1 = 'Reportagem excelente e com muitas informa√ß√µes sobre o ocorrido'
comentario_2 = 'Faltou muita informa√ß√£o que s√≥ quem mora aqui sabe'
comentario_3 = 'N√£o mudou em nada a minha opini√£o'
#
comentario_4 = 'A on√ßa n√£o tem culpa'
#
comentario_5 = 'O caseiro que alimentava ela'
comentario_6 = 'Isso √© culpa de quem alimentava ela'

modelo_demonstracao = modelo_noticia
mapeamento_demonstracao = {0: 'ruim', 1: 'neutra', 2: 'boa'}

comentarios = [comentario_1, comentario_2, comentario_3]

for texto in comentarios:
  logits = classificar_texto(texto, modelo_demonstracao, tokenizador, device)

  previsao = np.argmax(logits, axis=1).flatten()[0]

  previsao_desc = mapeamento_demonstracao[previsao]

  print(f'\nComent√°rio: "{texto}"')
  print(f'Previs√£o: {previsao_desc.upper()}')

modelo_demonstracao = modelo_onca
mapeamento_demonstracao = {0: 'negativo', 1: 'neutro', 2: 'positivo'}

logits = classificar_texto(comentario_4, modelo_demonstracao, tokenizador, device)

previsao = np.argmax(logits, axis=1).flatten()[0]

previsao_desc = mapeamento_demonstracao[previsao]

print(f'\nComent√°rio: "{comentario_4}"')
print(f'Previs√£o: {previsao_desc.upper()}')

modelo_demonstracao = modelo_caseiro

comentarios = [comentario_5, comentario_6]

for texto in comentarios:
  logits = classificar_texto(texto, modelo_demonstracao, tokenizador, device)

  previsao = np.argmax(logits, axis=1).flatten()[0]

  previsao_desc = mapeamento_demonstracao[previsao]

  print(f'\nComent√°rio: "{texto}"')
  print(f'Previs√£o: {previsao_desc.upper()}')